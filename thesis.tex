%-*- coding: UTF-8 -*-

\documentclass[UTF8]{article}



\usepackage{amsmath}
\usepackage{bm}
\usepackage{indentfirst}


\usepackage[standard, amsmath, thmmarks]{ntheorem}

\usepackage{clrscode3e}

\title{Generating Semi-algebraic Invariants for Non-autonomous Polynomial Hybrid Systems}
\author{Qiuye Wang}

\bibliographystyle{plain}

\begin{document}

\maketitle

\begin{abstract}
\end{abstract}

\section{Introduction}
\label{sec:introduction}
Hybrid systems are systems including both discrete and continuous dynamics. This feature enables them to be used in many real-world engineering problems. A typical one is MDD, which stands for Model-Driven Development\cite{giese2006survey}.

A core problem of verifying hybrid systems is so-called safety verification problem. It asks whether a hybrid system will reach some unsafe states from given initial states. Obviously, if we can compute the reachable set of given system, which includes all states reachable from initial states, then we can solve safety verification problem by simply examines whether any unsafe state is in reachable set or not \cite{clarke2003abstraction}. 

But for common differential equations, the reachable set is usually intractable, especially when time is unbounded. So the intuitive methods of directly computing reachable set can only be used for very special systems. To avoid the computing of reachable sets, methods based on invariants are brought up\cite{sankaranarayanan2004constructing, prajna2004safety}.

Invariants can be seen as a special kind of over-approximation of reachable set. Informally, invariants(or inductive invariants, if called precisely) are sets satisfying that current state included in invariants implies that states evolved from current state are all included in invariants. A virtue of invariants is that they can be computed without solving differential equations.

Non-autonomous hybrid systems, i.e. systems that evolution function $\boldsymbol{f}$ changes with time, are an important class of hybrid systems. Most previous works in that field focus on autonomous case, i.e. systems that evolution function $\boldsymbol{f}$ doesn't change with time \cite{liu2011computing}. In this article we will focus on non-autonomous case, We propose a sound and complete algorithm for verifying semi-algebraic invariants for non-autonomous polynomial hybrid system. From it, we obtain a sound and relatively complete algorithm for generating these invariants.

The basic idea is to transform the definition of continuous invariant of non-autonomous polynomial hybrid system into a first order formula of finite length, then use quantifier elimination algorithm to obtain a equivalent quantifier-free formula. When verifying, the original formula contains only bounded variables, so the corresponding quantifier-free  formula will be either \emph{TRUE} or \emph{FALSE}, which represents whether the verified semi-algebraic set is an invariant of our system or not. When generating, some free variables representing the coefficients of possible invariants are introduced. The resulting quantifier-free formula can be seen as a constraint on those coefficients. Any solution to the constraint yields a valid invariant, and a \emph{no solution} result denotes no invariant satisfies given template.

The main contribution of this article include: 
\begin{enumerate}
	\item we present a whole set of definitions for continuous invariants in non-autonomous case; 
	\item we give a sound and complete algorithm for verifying semi-algebraic invariants for polynomial hybrid systems.
	\item we give a sound and relatively complete algorithm for generating semi-algebraic invariants for polynomial hybrid systems.
%	\item we analyses time and space complexity of those algorithms and give primitive recursion upper bound for them.
\end{enumerate}

The article is organized as follows: Section \ref{sec:preliminaries} includes definitions and some background knowledge; Section \ref{sec:simple} illuminates our method using a simplified problem when initial sets, domain and invariants are all defined by a single polynomial; Section \ref{sec:general} gives detailed version of our algorithms which can be used in general semi-algebraic sets; we conclude the article with Section \ref{sec:conclusion}.

\section{Preliminaries}
\label{sec:preliminaries}
\subsection{Definitions}
The main difficulty in handling hybrid system is to deal with continuous dynamics. If we know how to verify or generate invariant for a certain mode of hybrid system, similar methods can be easily extended to the whole system, see \cite{prajna2004safety, kong2016invariant}. So for simplicity, we only consider single-mode hybrid systems:

\begin{Definition}[Hybrid System]
A hybrid system is a tuple $(\boldsymbol{H}, \boldsymbol{I}, \boldsymbol{f})$,  where: 
	\begin{enumerate}
		\item $\boldsymbol{H} \subseteq \mathbb{R}^n$  is the domain of system state.
		\item $\boldsymbol{I} \subseteq \boldsymbol{H}$ is the set of initial states, which will be called the initial set.
		\item $\boldsymbol{f} \in \boldsymbol{H} \times [0, +\infty) \rightarrow \mathbb{R}^n$ is the evolution function of system. The evolution of system subjects to: $\dot{\boldsymbol{x}}(t) = \boldsymbol{f}(\boldsymbol{x}(t),t)$.
	\end{enumerate}
\end{Definition}

\begin{Definition}[Trajectory]
For a hybrid system $M$, the trajectory originating from state $\boldsymbol{x}_0$ and time $t_0$ in time $T$ is a differentiable function $\boldsymbol{x} \in [t_0, t_0 + T) \rightarrow \mathbb{R}^n$ satisfies:
	\begin{enumerate}
		\item For $t \in [t_0, t_0 + T)$, $\dot{\boldsymbol{x}}(t) = \boldsymbol{f}(\boldsymbol{x}(t),t)$; and 
		\item $\boldsymbol{x}(t_0) = \boldsymbol{x}_0$.
	\end{enumerate}
	
When it's obvious from context, we will omit the phrase ``from $\boldsymbol{x}_0$'', ``from time $t_0$''.
\end{Definition}

\begin{Definition}[Safety]
Given an unsafe set $X_U \subseteq \mathbb{R}^n$,  we say a hybrid system is safe, if no trajectories satisfy: 
	\begin{enumerate}
		\item $\boldsymbol{x}(0) \in \boldsymbol{I}$; and
		\item $\exists \tau \geq 0 : \boldsymbol{x}(\tau) \in X_U$。
	\end{enumerate}
\end{Definition}

\begin{Definition}[Continuous Invariant]
\label{def:invariant}
The continuous invariant of a hybrid system $(\boldsymbol{H}, \boldsymbol{I}, \boldsymbol{f})$ is a set $\boldsymbol{A} \subseteq \mathbb{R}^n$ satisfies:
	\begin{enumerate}
		\item $\boldsymbol{I} \subseteq \boldsymbol{A}$, and 
		\item For any $t_0 \geq 0$, $\boldsymbol{x}_0 \in \boldsymbol{A}$ and $T > 0$, any trajectories $\boldsymbol{x}$ satisfying $\boldsymbol{x}(t_0) = \boldsymbol{x}_0$ also satisfy: $(\forall t \in [t_0, t_0 + T],\boldsymbol{x}(t) \in \boldsymbol{H}) \Rightarrow (\forall t \in [t_0,t_0 + T], \boldsymbol{x}(t) \in \boldsymbol{A})$。
	\end{enumerate}
\end{Definition}

In this article, the word \emph{invariant} always means continuous invariant defined here, if not state explicitly otherwise.

The main subject of our study is polynomial hybrid system: 
\begin{Definition}[Polynomial Hybrid System]
	We say a hybrid system $(\boldsymbol{H}, \boldsymbol{I}, \boldsymbol{f})$ is polynomial, if: 
	\begin{enumerate}
		\item Domain $\boldsymbol{H}$ is a semi-algebraic set;
		\item Initial set $\boldsymbol{I}$ is a semi-algebraic set;
		\item Evolution funtion $\boldsymbol{f}$ is a polynomial vector function for $t$ and $\boldsymbol{x}$. That is to say: every $f_i(\boldsymbol{x}, t)$ in $\boldsymbol{f}(\boldsymbol{x}, t) = (f_1(\boldsymbol{x}, t), f_2(\boldsymbol{x}, t), \dots, f_n(\boldsymbol{x}, t))$ satisfies: $f_i(\boldsymbol{x}, t) \in \mathbb{R}[\boldsymbol{x}, t]$, where $\mathbb{R}[\boldsymbol{x}, t]$ is a short version of $\mathbb{R}[x_1, x_2, \dots, x_n, t]$.
	\end{enumerate}
\end{Definition}

In this article, we always assume a hybrid system is polynomial, if not state explicitly otherwise.

It's easy to verify that polynomial functions satisfy Lipschitz condition. By the famous Picard-Lindel\"{o}f theorem, there exists a unique solution to the initial value problem locally.

\subsection{Background: Semi-algebraic Set} 
\begin{Definition}[Semi-algebraic Set]
\label{def:semialgebra}
A semi-algebraic set is a subset of $\mathbb{R}^n$ defined by a finite sequence of polynomial equations and inequalities , or any finite union of such sets.

Formally, a set $S \subseteq \mathbb{R}^n$ is a semi-algebraic set if and only if there exists formula $\psi$ such that $S = \{\boldsymbol{x} \in \mathbb{R}^n\ |\ \psi(x)\ \text{satisfies} \}$,  where $\psi$ defined by: 

\begin{displaymath}
	\psi \doteq \bigvee_{k=1}^{K} \bigwedge_{j=1}^{J_k}p_{kj} \rhd 0
\end{displaymath}
where $p_{kj} \in \mathbb{R}[\boldsymbol{x}]$ and $\rhd \in \{\geq, >\}$.
\end{Definition}

It's easy to prove that operations on semi-algebraic set is equivalent to corresponding operations on the formula defining it. More specifically, if we use $S(\psi)$ to represent semi-algebraic set defined by $\psi$, we have the following properties: 
\begin{itemize}
	\item $S(\psi_1) \cap S(\psi_2) = S(\psi_1 \wedge \psi_2)$
	\item $S(\psi_1) \cup S(\psi_2) = S(\psi_1 \vee \psi_2)$
	\item $S(\psi)^c = S(\neg \psi)$
	\item $S(\psi_1) \backslash S(\psi_2) = S(\psi_1) \cap S(\psi_2)^c = S(\psi_1 \wedge \neg \psi_2)$
\end{itemize}

\subsection{Background: Lie Derivatives}
Lie derivatives describe the change of a tensor field along the flow of another vector field. 

\begin{Definition}[Lie Derivatives]
\label{def:lieDeri}
For a given function $\phi$, a given vector function $\boldsymbol{f}(t, \boldsymbol{x})$, we define Lie derivatives $\mathcal{L}_{t, f}$ inductively as: 
\begin{align*}
	\mathcal{L}_{t, f}^0 \phi (\boldsymbol{x}) &= \phi (\boldsymbol{x}) \\
	\mathcal{L}_{t, f}^k \phi (\boldsymbol{x}) &= \langle \frac{\partial}{\partial \boldsymbol{x}} \mathcal{L}_{t, f}^{k-1} \phi (\boldsymbol{x}) \cdot  \boldsymbol{f}(\boldsymbol{x}, t) \rangle,\qquad k>0
\end{align*}

where $\langle * \cdot * \rangle$ is dot product.
\end{Definition}

\begin{Example}
	Assume $\boldsymbol{f}(x,y,t) = (-x+t,y-t)$ and $\phi (x,y) = x + y^2$, then: 
	\begin{align*}
		\mathcal{L}_{t, f}^0 \phi (x, y) &= x + y^2 \\
		\mathcal{L}_{t, f}^1 \phi (x, y) &= 2y^2 - 2ty -x + t \\
		\mathcal{L}_{t, f}^2 \phi (x, y) &= 4y^2 - 6ty -x + t \\
		\dots & \dots
	\end{align*}
\end{Example}

\begin{Definition}[Pointwise Rank]
\label{def:lieRank}
For a given state $\boldsymbol{x}$ and time $t$, we define pointwise rank of Lie derivatives as: 
\[
	\gamma_{f,\phi}(\boldsymbol{x}, t) = \min\{k \in \mathbb{N}\ |\ \mathcal{L}_{t, f}^k \phi (\boldsymbol{x}) \neq 0\}
\]
\end{Definition}

In this article we will just call \emph{pointwise rank} as \emph{rank}.

Note that Lie derivatives and their rank both contains variable t.

\subsection{Background: Polynomial Ideals Theory}
Polynomial ideal is a powerful tool when we deal with polynomial related problems. Here we recall some basic contents about it, from \cite{cox1992ideals}.

For a given field $\mathbb{K}$ and variables $x_1, x_2, \dots, x_n$, we can define polynomial ring over $\mathbb{K}$ as $\mathbb{K}[x_1, x_2, \dots, x_n]$. We write $\mathbb{K}[\boldsymbol{x}]$ to represent $\mathbb{K}[x_1, x_2, \dots, x_n]$ and always assume $\mathbb{K} = \mathbb{R}$, i.e. coefficients are real numbers. 

\begin{Definition}[Polynomial Ideals]
Given a polynomial ring $\mathbb{K}[\boldsymbol{x}]$, a subset $\boldsymbol{I} \subseteq \mathbb{K}[\boldsymbol{x}]$ is called ideal if:
	\begin{enumerate}
		\item $0 \in \boldsymbol{I}$;
		\item For any $p(x), q(x) \in \boldsymbol{I}$, we have: $p(x)+q(x) \in \boldsymbol{I}$;
		\item For any $p(x) \in \boldsymbol{I}$ and $h(x) \in \mathbb{K}[\boldsymbol{x}]$, we have: $p(x)h(x) = h(x)p(x) \in \boldsymbol{I}$.
	\end{enumerate}
\end{Definition}

\begin{Definition}[Generated Ideals]
we call
	\begin{displaymath}
		\boldsymbol{I} \doteq \bigcap_{p_1,p_2,\dots,p_k \in \boldsymbol{I}', \boldsymbol{I}'\text{is a ideal} }\boldsymbol{I}'
	\end{displaymath}
ideal generated by basis $p_1,p_2,\dots, p_k$, denoted by $\langle p_1, p_2, \dots, p_k \rangle$.

It's easy to prove that:
	\begin{displaymath}
		\langle p_1, p_2, \dots, p_k \rangle = \{\sum_{i=1}^k p_ih_i\ |\ \forall i : h_i \in \mathbb{K}[\boldsymbol{x}]\}
	\end{displaymath}
\end{Definition}

A well-known result is every polynomial ideal in real field can be generated by finite basis: 

\begin{Theorem}[Hibert's Basis Theorem]
Any polynomial ideal $\boldsymbol{I} \in \mathbb{R}[\boldsymbol{x}]$ can be generated by a finite class of basis. i.e. for any ideal $\boldsymbol{I} \in \mathbb{R}[\boldsymbol{x}]$, there exists $p_1, p_2, \dots, p_k \in \mathbb{R}[\boldsymbol{x}]$ such that $\boldsymbol{I} = \langle p_1, p_2, \dots, p_k \rangle$.
\end{Theorem}

The above theorem can take a different form: 
\begin{Theorem}[Ascending Chain Theorem]
\label{thm:ascendingChain}
For any infinite ascending chain of ideals in $\mathbb{K}[\boldsymbol{x}]$:
	\begin{equation*}
		\boldsymbol{I}_1 \subseteq \boldsymbol{I}_2 \subseteq \dots \boldsymbol{I}_k \subseteq \dots
	\end{equation*}
There exists $N$ such that for any $l \geq N$, $\boldsymbol{I}_l = \boldsymbol{I}_N$.
\end{Theorem}

\section{Simple Case}
\label{sec:simple}
In this section, we focus on a simplified version of our original problem. More specifically, we only consider invariants that can be defined by a single polynomial inequality $\phi(\boldsymbol{x}) \geq 0$, we use $\Phi$ to denote the invariant. Also we assume that the domain $\boldsymbol{H}$ and initial set $\boldsymbol{I}$ can be defined by a single polynomial inequality. We will use $\boldsymbol{H}(\boldsymbol{x}) \geq 0$ and $\boldsymbol{I}(\boldsymbol{x}) \geq 0$ to denote them separately. In this section, if not explicitly state otherwise, we always suppose our hybrid system takes that form.

\subsection{Intuitive Idea and Lie Deriavarives}
Intuitively, an invariant is a set that if any time system state falls in it, it will never come out of it. Suppose we follow the trajectory of our system: when system state is inside  $\Phi$, by the continuity of system trajectories, obviously it must reach the boundary of $\Phi$ before it comes out of $\Phi$. So the real danger of coming out of $\Phi$ occurs when system state is in the boundary of $\Phi$. In this simple case, that is to say: for every states $\boldsymbol{x}_0$ satisfying $\phi(\boldsymbol{x}_0) = 0$ and any time $t_0 \geq 0$, there exists some positive time $\epsilon$ such that the trajectory originating from state $\boldsymbol{x}_0$ and time $t_0$ in time $\epsilon$ doesn't decrease the value $\phi$. 

To turn this intuitive idea into practical algorithm, the first step is to find a tool to describe the change of $\phi$ as system evolves. Lie derivatives are suitable for this.

\begin{Theorem}
\label{thm:lieDeri}
Given polynomial $\phi$ and hybrid system $(\boldsymbol{H}, \boldsymbol{I}, \boldsymbol{f})$, $\gamma_{f, \phi}(\boldsymbol{x}_0, t) \neq 0$ if and only if $\boldsymbol{x}_0 \in S(\phi(\boldsymbol{x}) = 0)$,  and if we take $\boldsymbol{x}(t_0) = \boldsymbol{x}_0$, then it follows that: 
\begin{enumerate}
	\item if $\gamma_{f, \phi}(\boldsymbol{x}_0, t_0) < \infty$ and $\mathcal{L}_{t_0, f}^{\gamma_{f, \phi}(\boldsymbol{x}, t_0)} \phi (\boldsymbol{x}_0) > 0$, then:
		\begin{equation*}
			\exists \epsilon > 0, \forall t \in (t_0, t_0 + \epsilon),\phi (\boldsymbol{x}(t)) > 0
		\end{equation*}
	\item if $\gamma_{f, \phi}(\boldsymbol{x}_0, t_0) < \infty$ and $\mathcal{L}_{t_0, f}^{\gamma_{f, \phi}(\boldsymbol{x}, t_0)} \phi (\boldsymbol{x}_0) < 0$, then:
		\begin{equation*}
			\exists \epsilon > 0, \forall t \in (t_0, t_0 + \epsilon),\phi (\boldsymbol{x}(t)) < 0
		\end{equation*}
	\item if $\gamma_{f, \phi}(\boldsymbol{x}, t_0) = \infty$, then:
		\begin{equation*}
			\exists \epsilon > 0, \forall t \in (t_0, t_0 + \epsilon),\phi (\boldsymbol{x}(t)) = 0
		\end{equation*}
\end{enumerate}
\end{Theorem}

\begin{Proof}
First, recall Definition \ref{def:lieRank}, $\gamma_{f, \phi}(\boldsymbol{x}_0, t) \neq 0$ if and only if $\mathcal{L}_{t, f}^0 \phi (\boldsymbol{x}) = 0$, which, by Definition \ref{def:lieDeri}, is equivalent to $\phi(\boldsymbol{x}_0) = 0$. 

Next, assume now $\gamma_{f, \phi}(\boldsymbol{x}_0, t) \neq 0$. Since $\boldsymbol{f}$ is a polynomial vector function, we know $\boldsymbol{f}$ is analytic. So the initial value problem for differential equation $\dot{\boldsymbol{x}}(t) = \boldsymbol{f}(\boldsymbol{x}(t),t)$ and $\boldsymbol{x}(t_0) = \boldsymbol{x}_0$ exists a unique solution near $t_0$\cite{tenenbaum1963ordinary}. Since $\phi$ is also a polynomial function, we can conclude that $\phi(\boldsymbol{x}(t))$ is analytic near $t_0$. So we have: 
	\begin{equation*}
		\begin{split}
		\phi(\boldsymbol{x}(t)) &= \phi(\boldsymbol{x}(t_0)) + \frac{\mathrm{d} \phi}{\mathrm{d}t}(t_0) * (t-t_0) + \frac{\mathrm{d}^2 \phi}{\mathrm{d}t^2} * \frac{(t-t_0)^2}{2!} + \dots \\
							&= {\mathcal{L}_{t_0, f}^0 \phi(\boldsymbol{x}_0)} + \mathcal{L}_{t_0, f}^1 \phi(\boldsymbol{x}_0) * (t-t_0) + \mathcal{L}_{t_0, f}^2 \phi(\boldsymbol{x}_0) * \frac{(t-t_0)^2}{2!} + \dots
		\end{split}
	\end{equation*}
satisfies near $t_0$.

For the first two situations, we see that the first $\gamma_{f, \phi}(\boldsymbol{x}_0, t_0)$ terms of the right side equation is equal to 0, and the coefficient of the dominant term has the same sign as $\mathcal{L}_{t_0, f}^{\gamma_{f, \phi}(\boldsymbol{x}, t_0)} \phi (\boldsymbol{x}_0)$, so we can immediately get the corresponding conclusions. 

As to the last situation, $\gamma_{f, \phi}(\boldsymbol{x}, t_0) = \infty$ implies that every term of the right side expansion is equal to 0, which means $\phi (\boldsymbol{x}(t)) =0$ satisfies in the interval where unique solution exists and $\phi$ is analytic.
\end{Proof}

Note the three situations in theorem \ref{thm:lieDeri} include all possible value of $\mathcal{L}_{t_0, f}^{k}$, so an inverse version of this theorem is possible, we state it as a corollary: 

\begin{Corollary}
\label{cor:lieDeri}
For a sequence $\{ t_i \}$  satisfying $t_i > t_0$ and $\lim_{i \to \infty} t_i = t_0$, we have: 
\begin{enumerate}
	\item if for all i, $\phi(\boldsymbol{x}(t_i)) > 0$, then $\gamma_{f, \phi}(\boldsymbol{x}_0, t_0) < \infty$ and $\mathcal{L}_{t_0, f}^{\gamma_{f, \phi}(\boldsymbol{x}_0, t_0)} \phi (\boldsymbol{x}_0) > 0$; 
	\item if for all i, $\phi(\boldsymbol{x}(t_i)) < 0$, then $\gamma_{f, \phi}(\boldsymbol{x}_0, t_0) < \infty$ and $\mathcal{L}_{t_0, f}^{\gamma_{f, \phi}(\boldsymbol{x}_0, t_0)} \phi (\boldsymbol{x}_0) < 0$;
	\item if for all i, $\phi(\boldsymbol{x}(t_i)) = 0$, then $\gamma_{f, \phi}(\boldsymbol{x}_0, t_0) = \infty$; 
\end{enumerate}
\end{Corollary}

\subsection{Transverse Set and Invariant}
We use Lie derivatives to define \emph{transverse set} :

\begin{Definition}[Transverse Set]
\label{def:trans}
	Given a hybrid system $(\boldsymbol{H}, \boldsymbol{I}, \boldsymbol{f})$, we define transverse set of region $S(p(\boldsymbol{x}) \geq 0)$ as: 
	\begin{equation*}
		Trans_{f \uparrow p}^{(t)} \doteq \{\boldsymbol{x} \in \mathbb{R}^n | \gamma_{f, p}(\boldsymbol{x}, t) < \infty \wedge \mathcal{L}_{t, f}^{\gamma_{f, p}(\boldsymbol{x}, t)} p(\boldsymbol{x}) < 0 \}
	\end{equation*}
\end{Definition}

Intuitively, transverse set of region $S(p(\boldsymbol{x}) \geq 0)$ contains elements that are either not in the region or will leave the region(as system evolves from time $t$) immediately.

Using transverse set, we can give the necessary and sufficient condition of continuous invariants:

\begin{Theorem}
\label{thm:trans}
Given a hybrid system $(\boldsymbol{H}, \boldsymbol{I}, \boldsymbol{f})$, $S(\phi(\boldsymbol{x}) \geq 0)$ is an invariant of the system if and only if:
	\begin{enumerate}
		\item It contains the initial set $\boldsymbol{I}$. Which is: 
			\begin{equation*}
				(\boldsymbol{I}(\boldsymbol{x}) \geq 0) \Rightarrow (\phi(x) \geq 0)
			\end{equation*}
		\item Any time, as long as system evolves within its domain, any state in the boundary $S(\phi(\boldsymbol{x}) = 0)$ will not come out of the region $S(\phi(\boldsymbol{x}) \geq 0)$. Which is:
			\begin{equation*}
				(\phi(\boldsymbol{x}) = 0) \Rightarrow (\forall t>0: \boldsymbol{x} \in (Trans_{f \uparrow \phi}^{(t)})^c \cup Trans_{f \uparrow H}^{(t)})
			\end{equation*}
	\end{enumerate}
\end{Theorem}

\begin{Proof}
First we consider the necessary part. If the first condition is not satisfied, which means $(\boldsymbol{I}(\boldsymbol{x}) \geq 0) \nRightarrow (\phi(x) \geq 0)$, that is to say $\boldsymbol{I} \not\subseteq S(\phi(\boldsymbol{x}) \geq 0)$, which contradicts the first condition of Definition \ref{def:invariant}.

Now if the second condition is not satisfied, which means: there exists $\boldsymbol{x}_0$ and $t_0 > 0$ such that $\phi(\boldsymbol{x_0}) = 0$ and $\boldsymbol{x}_0 \in Trans_{f \uparrow \phi}^{(t_0)} \cap (Trans_{f \uparrow H}^{(t_0)})^c$. Then by Definition \ref{def:trans} and Theorem \ref{thm:lieDeri} we know: 
\begin{equation*}
		\exists \epsilon > 0, \forall t \in (t_0, t_0 + \epsilon), (\boldsymbol{H}(\boldsymbol{x}(t)) \geq 0) \cap (\phi(\boldsymbol{x}(t) < 0))
\end{equation*}
which contradicts the second condition of Definition \ref{def:invariant}. That concludes the proof for the necessary part.

Next, let's consider the sufficient part. It's easy to see that the first condition of this theorem is essentially the same as the first condition of Definition \ref{def:invariant}. So we only need to prove $S(\phi(\boldsymbol{x}) \geq 0)$ also satisfies the second condition of Definition \ref{def:invariant}. Suppose the second condition doesn't satisfy, which means there exists $t_0 \geq 0$, $\boldsymbol{x}_0 \in S(\phi(\boldsymbol{x}) \geq 0)$ and $T_0 > 0$ such that for a certain trajectory $\boldsymbol{x}(t_0) = \boldsymbol{x}_0$, the following satisfies: 
	\begin{equation*}
		(\forall t \in [t_0, t_0 + T_0], \boldsymbol{x}(t) \in \boldsymbol{H}) \nRightarrow (\forall t \in [t_0, t_0 + T_0], \boldsymbol{x}(t) \in S(\phi(\boldsymbol{x}) \geq 0))
	\end{equation*}
which is equivalent to: 
	\begin{equation*}
		(\forall t \in [t_0, t_0 + T_0], \boldsymbol{H}(\boldsymbol{x}(t)) \geq 0) \wedge (\exists t \in [t_0, t_0 + T_0], \phi(\boldsymbol{x}(t)) < 0)
	\end{equation*}
Now consider $\phi(\boldsymbol{x}(t))$ as a function. We know that $\phi(\boldsymbol{x}(t_0)) = \phi(\boldsymbol{x}_0) \geq 0$ and for some $t_c \in [t_0, t_0 + T_0]$, $\phi(\boldsymbol{x}(t_c)) < 0$. By the continuity of $\boldsymbol{x}$, there exists $t_z \in [t_0, t_c)$ such that $\phi(\boldsymbol{x}(t_z) = 0)$, which means the set $\{ t \in [t_0, t_c)\ |\ \phi(\boldsymbol{x}(t)) = 0 \}$ is not empty.

Take $t_m \doteq \sup\{t \in [t_0, t_c]\ |\ \phi (\boldsymbol{x}(t)) = 0 \}$, By the definition of supremum and continuity of $\phi(\boldsymbol{x}(t))$, $\phi(\boldsymbol{x}(t_m)) = 0$. Denote $\boldsymbol{x}(t_m)$ by $\boldsymbol{x}_m$. As $t_m$ is the rightmost zero point of $\phi(\boldsymbol{x}(t))$, $\phi(\boldsymbol{x}(t_c)) < 0$, we know: $\forall t \in (t_m, t_c),\phi(\boldsymbol{x}(t)) < 0$. Use Corollary \ref{cor:lieDeri}, we get:  $\gamma_{f, \phi}(\boldsymbol{x}_m, t_m) < \infty$ and $\mathcal{L}_{t_m, f}^{\gamma_{f, \phi}(\boldsymbol{x}_m, t_m)} \phi (\boldsymbol{x}(t_m)) < 0$. Recall Definition \ref{def:trans}, that is exactly $\boldsymbol{x}_m \in Trans_{f \uparrow \phi}^{(t_m)}$.

Since $\forall t \in [t_0, t_0 + T_0], \boldsymbol{H}(\boldsymbol{x}(t)) \geq 0$, certainly there is: $\forall t \in (t_m, t_c),\boldsymbol{H}(\boldsymbol{x}(t)) \geq 0$. Combine the first and third situation of Corollary \ref{cor:lieDeri}, we get: 
\begin{enumerate}
	\item $\gamma_{f, \phi}(\boldsymbol{x}_m, t_m) < \infty$ and $\mathcal{L}_{t_m, f}^{\gamma_{f, \phi}(\boldsymbol{x}_m, t_m)} \phi (\boldsymbol{x}(t_m)) > 0$, or: 
	\item $\gamma_{f, \phi}(\boldsymbol{x}_m, t_m) = \infty$; 
\end{enumerate}
Either way, we have: $\boldsymbol{x}_m \notin Trans_{f \uparrow H}^{(t_m)}$.

But $\phi(\boldsymbol{x}_m) = 0$, that contradicts the second condition of this theorem. That concludes the proof for the sufficient part.
\end{Proof}

\subsection{Ideals Generated by Lie Derivatives}
\label{sub:original}
The problem of Definition \ref{def:trans} is that it involves infinity. This subsection aims to prove that either the rank of Lie derivative is infinity, or it's less than a computable upper-bound $N$. The main tool used will be ideals generated by Lie derivatives: 

\begin{Definition}[Ideal Generated by Lie Derivatives]
\label{def:lieIdeal}
Given polynomial hybrid system $(\boldsymbol{H}, \boldsymbol{I}, \boldsymbol{f})$ and polynomial $\phi(\boldsymbol{x})$,in $\mathbb{R}[\boldsymbol{x}]$ we call: 
		\begin{equation*}
			\boldsymbol{I}_k^{(t)} \doteq \langle \mathcal{L}_{t, f}^0 \phi(\boldsymbol{x}), \mathcal{L}_{t, f}^1 \phi(\boldsymbol{x}), \dots, \mathcal{L}_{t, f}^k \phi(\boldsymbol{x}) \rangle
		\end{equation*}
		as the k-th ideal generated by Lie derivatives. Also call: 
		\begin{equation*}
			\boldsymbol{I}^{(t)} \doteq \bigcup_k \boldsymbol{I}_k^{(t)}
		\end{equation*}
		as the ideal generated by Lie derivatives. where $t \in \mathbb{R}$ is a parameter.
\end{Definition}
We should note here $t$ is considered to be a parameter in $\mathbb{R}$.

We want to prove that the ideal generated by Lie derivatives can be computed by finite steps of operations, to prove the above theorem, we will need an extra definition: 

\begin{Definition}[Total Ideal Generated by Lie Derivatives]
\label{def:lieTot}
Consider $\mathcal{L}_{t, f}^k \phi(\boldsymbol{x})$ to be a element of $\mathbb{R}[t, \boldsymbol{x}]$, we call: 
	\begin{equation*}
		\boldsymbol{I}_k \doteq \langle \mathcal{L}_{t, f}^0 \phi(\boldsymbol{x}), \mathcal{L}_{t, f}^1 \phi(\boldsymbol{x}), \dots, \mathcal{L}_{t, f}^k \phi(\boldsymbol{x}) \rangle
	\end{equation*}	
	as the k-th total ideal generated by Lie derivatives. Also call:
	\begin{equation*}
		\boldsymbol{I} \doteq \bigcup_k \boldsymbol{I}_k
	\end{equation*}
	as the ideal generated by Lie derivatives.
\end{Definition}
We see that total ideal is just to consider $t$ as a variable rather than parameter.

Now we are ready to prove the main theorem of this subsection: 
\begin{Theorem}
\label{thm:lieIdeal}
There exists $N \in \mathbb{N}$ such that for every $t \in \mathbb{R}$, $\boldsymbol{I}^{(t)} = \boldsymbol{I}_N^{(t)}$.
\end{Theorem}

\begin{Proof}
Total ideals generated by Lie derivatives form an ascending ideal chain:
\begin{equation*}
	\boldsymbol{I}_0 \subseteq \boldsymbol{I}_1 \subseteq \dots \subseteq \boldsymbol{I}_{k} \subseteq \dots
\end{equation*}

By Theorem \ref{thm:ascendingChain}, we know that there exists $N$ such that for any $l \geq N$, $\boldsymbol{I}_l = \boldsymbol{I}_N$, which means $\boldsymbol{I}_N = \boldsymbol{I}$.

Now for arbitrary $t \in \mathbb{R}$, we assert that $\boldsymbol{I}_N^{(t)} = \boldsymbol{I}^{(t)}$. To see this, let's first explore the total ideal chain. To say $\boldsymbol{I}_N = \boldsymbol{I}$ is to say for any $l \geq N$, $\mathcal{L}_{t, f}^l \phi  \in \langle \mathcal{L}_{t, f}^0 \phi, \mathcal{L}_{t, f}^1 \phi, \dots, \mathcal{L}_{t, f}^N \phi \rangle$, which means there exists $\{ g_j \} \in \mathbb{R} [t, \boldsymbol{x}]$ such that:
	\begin{equation*}
		\mathcal{L}_{t, f}^l \phi = \sum_{0 \leq j \leq N} g_j \mathcal{L}_{t, f}^j \phi
	\end{equation*}
Substitute the value of $t$ into it, we get:
	\begin{equation*}
		\mathcal{L}_{t, f}^l \phi = \sum_{0 \leq j \leq N} g'_j \mathcal{L}_{t, f}^j \phi
	\end{equation*}
where $\{ g'_j \} \in \mathbb{R} [\boldsymbol{x}]$, this equation holds in $\mathbb{R} [\boldsymbol{x}]$. 

So we have: for any $t \in \mathbb{R}$, any $l \geq N$, $\mathcal{L}_{t, f}^l \phi  \in \boldsymbol{I}_N^{(t)}$ holds. That leads to our final conclusion.
\end{Proof}

\begin{Corollary}
\label{cor:lieRank}
There exists $N \in \mathbb{N}$ which is independent to $\boldsymbol{x}$ and $t$ such that $\gamma_{f, \phi}(\boldsymbol{x}, t) < \infty$ if and only if $\gamma_{f, \phi}(\boldsymbol{x}, t) \leq N$.
\end{Corollary}
\begin{Proof}
The sufficient part is obvious. We only need to consider the necessary part.

Take the $N$ in Theorem \ref{thm:lieIdeal}, suppose $\gamma_{f, \phi}(\boldsymbol{x}, t) > N$, since $\boldsymbol{I}_N = \boldsymbol{I}$, we have:  $\mathcal{L}_{t, f}^{\gamma_{f, p}(\boldsymbol{x}, t)} p(\boldsymbol{x}) \in \boldsymbol{I}_N$. So: 
\begin{equation*}
	 \mathcal{L}_{t, f}^{\gamma_{f, p}(\boldsymbol{x}, t)} p(\boldsymbol{x}) = \sum_{0 \leq j \leq N} g_j \mathcal{L}_{t, f}^j p(\boldsymbol{x})
\end{equation*}
But with $\gamma_{f, \phi}(\boldsymbol{x}, t) > N$, for $0 \leq j \leq N$ we have: $\mathcal{L}_{t, f}^j p(\boldsymbol{x}) = 0$. Substitute it into last equation we get:  $\mathcal{L}_{t, f}^{\gamma_{f, p}(\boldsymbol{x}, t)} = 0$, which contradicts Definition \ref{def:lieRank}.
\end{Proof}

Next we will present an algorithm to find such a $N \in \mathbb{N}$. First we give a lemma: 
\begin{Lemma}[Fixed Point Theorem]
\label{lem:fixed}
If for some $i$ we have: 
	\begin{equation*}
		\mathcal{L}_{t, f}^{i+1} \phi \in \boldsymbol{I}_i^{(t)}
	\end{equation*}
	then for any $m>i$: 
	\begin{equation*}
		\mathcal{L}_{t, f}^{m} \phi \in \boldsymbol{I}_i^{(t)}
	\end{equation*}
\end{Lemma}

\begin{Proof}
To prove this lemma, we use induction. The situation $m = i+1$ is exactly what we already have. Suppose we have proved for some $k > i$, the lemma holds. Now we consider the situation $m = k+1$. From induction hypothesis, we know: 
		\begin{equation*}
			\mathcal{L}_{t, f}^k \phi \in \langle \mathcal{L}_{t, f}^0 \phi, \mathcal{L}_{t, f}^1 \phi, \dots, \mathcal{L}_{t, f}^i \phi \rangle
		\end{equation*}
that is, for $0 \leq j \leq i$, there exists $\{ g_j \} \in \mathbb{R} [\boldsymbol{x}]$ such that: 
		\begin{equation*}
			\mathcal{L}_{t, f}^k \phi = \sum_{0 \leq j \leq i} g_j \mathcal{L}_{t, f}^j \phi
		\end{equation*}

Now for $\mathcal{L}_{t, f}^{k+1} \phi$,  By Definition \ref{def:lieDeri}:
		\begin{equation*}
		\begin{split}
			\mathcal{L}_{t, f}^{k+1} \phi &= \langle \frac{\partial}{\partial \boldsymbol{x}} \mathcal{L}_{t, f}^{k} \phi (\boldsymbol{x}) \cdot  \boldsymbol{f} \rangle \\
								&= \langle \frac{\partial}{\partial \boldsymbol{x}} \sum_{0 \leq j \leq i} g_j \mathcal{L}_{t, f}^j \phi \cdot \boldsymbol{f} \rangle \\
								&= \sum_{0 \leq j \leq i} \langle \mathcal{L}_{t, f}^j \phi \frac{\partial}{\partial \boldsymbol{x}} g_j \cdot \boldsymbol{f} \rangle + \sum_{0 \leq j \leq i} \langle g_j \frac{\partial}{\partial \boldsymbol{x}} \mathcal{L}_{t, f}^j \phi \cdot \boldsymbol{f} \rangle \\
								&= \sum_{0 \leq j \leq i} \langle \frac{\partial}{\partial \boldsymbol{x}} g_j \cdot \boldsymbol{f} \rangle \mathcal{L}_{t, f}^j \phi + \sum_{0 \leq j \leq i} g_j \mathcal{L}_{t, f}^{j+1} \phi  \\
								&= \sum_{0 \leq j \leq i} \langle \frac{\partial}{\partial \boldsymbol{x}} g_j \cdot \boldsymbol{f} \rangle \mathcal{L}_{t, f}^j \phi + \sum_{0 \leq j < i} g_j \mathcal{L}_{t, f}^{j+1} \phi + g_i \mathcal{L}_{t, f}^{i+1} \phi
		\end{split}
		\end{equation*}
Recall the condition of this lemma, there is: $\mathcal{L}_{t, f}^{i+1} \phi \in \langle \mathcal{L}_{t, f}^0 \phi, \mathcal{L}_{t, f}^1 \phi, \dots, \mathcal{L}_{t, f}^i \phi \rangle$. So in summary:
		\begin{equation*}
			\mathcal{L}_{t, f}^{k+1} \in  \langle \mathcal{L}_{t, f}^0 \phi, \mathcal{L}_{t, f}^1 \phi, \dots, \mathcal{L}_{t, f}^i \phi \rangle = \boldsymbol{I}_i^{(t)}
		\end{equation*}
That concludes our proof for this lemma.
\end{Proof}

The basic frame of our algorithm is: 
\begin{codebox}
\Procname{$\proc{Computing Upper Bound N: Original}$}
\li 	$i \gets 0$, $\boldsymbol{B} \gets \{ \mathcal{L}_{t, f}^0 \}$
\li 	\While \const{true}
\li		\Do
			Compute $\mathcal{L}_{t, f}^{i+1}$ from $\mathcal{L}_{t, f}^i$
\li			Generate ideal $\boldsymbol{I}$ from basis $\boldsymbol{B}$ \Indentmore
\zi			Ask whether $\mathcal{L}_{t, f}^{i+1} \in \boldsymbol{I}$ using Gr\"{o}bner basis 
\li			\If $\mathcal{L}_{t, f}^{i+1} \notin \boldsymbol{I}$
\li				\Then 
					$\boldsymbol{B} \gets \boldsymbol{B} \cup \{ \mathcal{L}_{t, f}^{i+1} \}$
\li					$i \gets i+1$
\li				\Else
\li					\kw{break}
				\End
		\End
\li	$N \gets i$
\end{codebox}

This is just a naive implement of Lemma \ref{lem:fixed}. Next subsection we will give an alternative algorithm to compute the upper bound $N$.

\subsection{Alternative Algorithm to Compute N}
\label{sub:alternative}
The algorithm we present in last subsection computes $N$ using Gr\"{o}bner basis, which is a rather ``expensive'' operation. Here we present an algorithm that avoids Gr\"{o}bner basis, but may give a larger $N$ comparing to the original algorithm. To achieve that goal, let's first consider monomial ideals:

\begin{Definition}
\label{def:monomialIdeal}
A monomial ideal of $\mathbb{R}[\boldsymbol{x}]$ is an ideal that can be generated by a finite set of monomials. More specifically, $\boldsymbol{I}$ is a monomial ideal of $\mathbb{R}[\boldsymbol{x}]$ if and only if: 
\begin{displaymath}
	\boldsymbol{I} = \langle m_1, m_2, \dots, m_k \rangle 
\end{displaymath}
where $m_i$ is a monomial in $\mathbb{R}[\boldsymbol{x}]$.
\end{Definition}

We use $m(p)$ to represent the leading term of polynomial $p$ i.e. term that has the largest order. For an ideal $\boldsymbol{I} = \langle p_0, p_1, \dots, p_k \rangle$, we define $m(\boldsymbol{I}) \doteq \langle m(p_0), m(p_1), \dots, m(p_k) \rangle$. When order monomials, we use the \emph{degree-lexicographic order}, which is a total ordering compatible with the natural graduation by total degree. 

We start with a lemma:

\begin{Lemma}
\label{lem:monomialChain}
Given polynomials $p_0, p_1, \dots, p_n$. Let $\boldsymbol{I}_i = \langle p_0, \dots, p_i \rangle$. if: 
	\begin{equation*}
		\boldsymbol{I}_0 \subsetneq \boldsymbol{I}_1 \subsetneq \dots \subsetneq \boldsymbol{I}_n
	\end{equation*}
then: 
	\begin{equation*}
		m(\boldsymbol{I}_0) \subsetneq m(\boldsymbol{I}_1) \subsetneq \dots \subsetneq m(\boldsymbol{I}_n)
	\end{equation*}
\end{Lemma}

\begin{Proof}
We prove this lemma step by step. For $\boldsymbol{I}_i$, since $\boldsymbol{I}_i \subsetneq \boldsymbol{I}_{i+1}$, we know that $p_{i+1} \notin \boldsymbol{I}_i$. If $m(\boldsymbol{p}_{i+1}) \notin m(\boldsymbol{I}_i)$, then $m(\boldsymbol{I}_i) \subsetneq m(\boldsymbol{I}_{i+1})$. Otherwise there is some $j \leq i$ such that $m(p_j)$ divides $m(p_{i+1})$. In that case, substitute $p_{i+1}$ with non-zero rest $p'_{i+1}$ of ordered division of $p_{i+1}$ by $p_j$, note $\boldsymbol{I}_k$ and $m(\boldsymbol{I}_k)$ stay unchanged. As the order of $p'_{i+1}$ drops, the process will end in finite steps, so we also have $m(\boldsymbol{I}_i) \subsetneq m(\boldsymbol{I}_{i+1})$.

Take $i$ from $0$ to $n-1$, we get the conclusion of this lemma.
\end{Proof}

Now we can give the alternative algorithm to compute $N$:

\begin{codebox}
\Procname{$\proc{Computing Upper Bound N: Alternative}$}
\li 	$i \gets 0$, $p_0 \gets \mathcal{L}_{t, f}^0$, $\boldsymbol{B} \gets \{ m(p_0) \}$
\li 	\While \const{true}
\li		\Do
			Compute $\mathcal{L}_{t, f}^{i+1}$ from $\mathcal{L}_{t, f}^i$, $p_{i+1} \gets \mathcal{L}_{t, f}^{i+1}$
\li			\While $p_{i+1} \neq 0$ and there exists $m(p_j) \in \boldsymbol{B}$ divides $m(p_{i+1})$
\li				\Do
					$p_{i+1} \gets$ rest of ordered division of $p_{i+1}$ by $p_j$
				\End
\li			\If $p_{i+1}$ equals to $0$
\li				\Then
					\kw{break}
				\End
\li			$\boldsymbol{B} \gets \boldsymbol{B} \cup \{ m(p_{i+1}) \}$
\li			$i \gets i+1$
		\End
\li	$N \gets i$
\end{codebox}

Every time the inside while loop executed, the degree of $p_{i+1}$ strictly drops. So the inside while loop can only be executed finite times. As for the outer loop, it's easy to prove $\boldsymbol{B}$ of each loop execution generates a strictly ascending ideal chain, so by Theorem \ref{thm:ascendingChain} it also ends after finite times of execution. 

When the program terminates, when have $m(\boldsymbol{I}_{i+1}) = m(\boldsymbol{I}_i)$. By Lemma \ref{lem:monomialChain}, $i$ satisfies the condition $\boldsymbol{I}_{i+1} = \boldsymbol{I}_i$, so it is a valid upper bound $N$.

\subsection{Verify Invariants of Hybrid System: Simple Case}
Now, with previous discussions, we are ready to give the algorithm to verify invariant of hybrid system. To do this, first we translate the conditions of Theorem \ref{thm:trans} into first order logic formula of finite length, then use quantifier elimination to get the equivalent quantifier-free formula. Since all variables are bounded, the resulting quantifier-free formula will be either \emph{TRUE} or \emph{FALSE}. \emph{TRUE} means the possible invariant is indeed an invariant of our hybrid system, while \emph{FALSE} means it is not an invariant of out hybrid system. First let's see how to do the translate: 

\begin{Theorem}
\label{thm:translate}
Given a hybrid system $(\boldsymbol{H}, \boldsymbol{I}, \boldsymbol{f})$ and a polynomial $\phi(\boldsymbol{x})$. We can construct a finite length formula $\theta(\phi ,\boldsymbol{H}, \boldsymbol{f}, \boldsymbol{x}, t)$ such that $\phi(\boldsymbol{x}) \geq 0$ is an invariant if and only if formula
		$(\boldsymbol{I}(\boldsymbol{x}) \geq 0) \rightarrow (\phi(\boldsymbol{x}) \geq 0)$
and formula
		$\theta(\phi ,\boldsymbol{H}, \boldsymbol{f}, \boldsymbol{x}, t)$
all satisfy.
\end{Theorem}

\begin{Proof}
Recall Theorem \ref{thm:trans}. Obviously, $\boldsymbol{I} \subseteq S(\phi(\boldsymbol{x}) \geq 0)$ if and only if formula
	\begin{equation*}
		(\boldsymbol{I}(\boldsymbol{x}) \geq 0) \rightarrow (\phi(\boldsymbol{x}) \geq 0)
	\end{equation*}
satisfies.

Now by Definition \ref{def:trans}, $\forall t \geq 0, \boldsymbol{x} \in (Trans_{f \uparrow \phi}^{(t)})^c \cup Trans_{f \uparrow H}^{(t)}$ if and only if:
	\begin{equation*}
		\forall t \geq 0, \neg(\gamma_{f, \phi}(\boldsymbol{x}, t) < \infty \wedge \mathcal{L}_{t, f}^{\gamma_{f, \phi}(\boldsymbol{x}, t)} < 0) \vee (\gamma_{f, \boldsymbol{H}}(\boldsymbol{x}, t) < \infty \wedge \mathcal{L}_{t, f}^{\gamma_{f, H}(\boldsymbol{x}, t)} <0)
	\end{equation*}
Use Corollary \ref{cor:lieRank}, it's equivalent to:
	\begin{equation*}
		\forall t \geq 0, \neg(\gamma_{f, \phi}(\boldsymbol{x}, t) \leq N \wedge \mathcal{L}_{t, f}^{\gamma_{f, \phi}(\boldsymbol{x}, t)} < 0) \vee (\gamma_{f, \boldsymbol{H}}(\boldsymbol{x}, t) \leq N \wedge \mathcal{L}_{t, f}^{\gamma_{f, H}(\boldsymbol{x}, t)} <0)
	\end{equation*}
for a computable natural number $N$.

If we take:
	\begin{align*}
		\pi^{(0)}(\phi, \boldsymbol{f}, \boldsymbol{x}, t) &\doteq \phi(\boldsymbol{x}) < 0 \\
		\pi^{(i)}(\phi, \boldsymbol{f}, \boldsymbol{x}, t) &\doteq (\bigwedge_{0 \leq j < i} \mathcal{L}_{t, f}^j \phi(\boldsymbol{x}) = 0) \wedge \mathcal{L}_{t, f}^i \phi(\boldsymbol{x}) < 0 \qquad i > 0
	\end{align*}
and let:
	\begin{equation*}
		\pi(\phi, \boldsymbol{f}, \boldsymbol{x}, t) \doteq \bigvee_{0 \leq i \leq N} \pi^{(i)}(\phi, \boldsymbol{f}, \boldsymbol{x}, t)
	\end{equation*}
then $\forall t \geq 0, \boldsymbol{x} \in (Trans_{f \uparrow \phi}^{(t)})^c \cup Trans_{f \uparrow H}^{(t)}$ if and only if formula
	\begin{equation*}
		\forall t ((t \geq 0) \rightarrow (\neg \pi(\phi, \boldsymbol{f}, \boldsymbol{x}, t) \vee \pi(\boldsymbol{H}, \boldsymbol{f}, \boldsymbol{x}, t)))
	\end{equation*}
which is equivalent to formula:
	\begin{equation*}
		\forall t ((t < 0) \vee (\pi(\phi, \boldsymbol{f}, \boldsymbol{x}, t) \wedge \neg \pi(\boldsymbol{H}, \boldsymbol{f}, \boldsymbol{x}, t)))
	\end{equation*}
satisfies.

Now the second condition of Theorem \ref{thm:trans} can be translated into:
	\begin{equation*}
		\theta(\phi ,\boldsymbol{H}, \boldsymbol{f}, \boldsymbol{x}, t) \doteq (\phi(\boldsymbol{x}) = 0) \rightarrow (\forall t ((t < 0) \vee (\pi(\phi, \boldsymbol{f}, \boldsymbol{x}, t) \wedge \neg \pi(\boldsymbol{H}, \boldsymbol{f}, \boldsymbol{x}, t))))
	\end{equation*}
\end{Proof}

The basic structure of our verifying algorithm is as follows:
\begin{enumerate}
	\item Use the original or alternative algorithm to compute the upper bound $N$ for $\phi$ and $\boldsymbol{f}$.
	\item Construct $\theta(\phi ,\boldsymbol{H}, \boldsymbol{f}, \boldsymbol{x}, t)$ as in the proof of Theorem \ref{thm:translate}.
	\item Apply quantifier elimination algorithms on formula $\forall \boldsymbol{x} (\theta(\phi, \boldsymbol{H}, \boldsymbol{f}, \boldsymbol{x}, t) \wedge ((\boldsymbol{I}(\boldsymbol{x}) \geq 0) \rightarrow (\phi(\boldsymbol{x}) \geq 0)))$.
	\item If the result is \emph{TRUE}, then $\phi(\boldsymbol{x}) \geq 0$ is an invariant; if the result is \emph{FALSE}, then $\phi(\boldsymbol{x}) \geq 0$ is not an invariant.
\end{enumerate}

\subsection{Generate Invariants of Hybrid System: Simple Case}
Using the notion of \emph{template}, we can derive an algorithm to generate invariants of hybrid system from the algorithm we presented in last subsection. A template is a parametrized polynomial $p(\boldsymbol{u}, \boldsymbol{x}) \in \mathbb{R}[u_1, u_2, \dots, u_m, x_1, x_2, \dots, x_n]$ where $u_1, u_2, \dots, u_m$ are parameters. Our target is to find an invariant $\phi(\boldsymbol{x})$ such that for some $\boldsymbol{u}_0$, $p(\boldsymbol{u}_0, \boldsymbol{x}) = \phi(\boldsymbol{x})$, or report error if no such invariant exists.

First we notice that Theorem \ref{thm:lieIdeal} and related corollaries can be extended to situation when the number of parameters is more than one: 
\begin{Lemma}
\label{cor:paraLieRank}
There exists $N \in \mathbb{N}$ which is independent to $\boldsymbol{x}$ and $t$ and $\boldsymbol{u}$ such that $\gamma_{f, \phi}(\boldsymbol{x}, t) < \infty$ if and only if $\gamma_{f, \phi}(\boldsymbol{x}, t) \leq N$.
\end{Lemma}
Also, the original and alternative algorithm both work for multiple parameters. Now we give the structure of our generating algorithm:
\begin{enumerate}
	\item Set a template $p(\boldsymbol{u}, \boldsymbol{x}) \in \mathbb{R}[\boldsymbol{u},\boldsymbol{x}]$.
	\item Use the original or alternative algorithm to compute the upper bound $N$ for $p$ and $\boldsymbol{f}$.
	\item Construct $\theta(p ,\boldsymbol{H}, \boldsymbol{f},\boldsymbol{u}, \boldsymbol{x}, t)$ as in the proof of Theorem \ref{thm:translate}.
	\item Apply quantifier elimination algorithms on formula $\forall \boldsymbol{x} (\theta(p, \boldsymbol{H}, \boldsymbol{f}, \boldsymbol{u}, \boldsymbol{x}, t) \wedge ((\boldsymbol{I}(\boldsymbol{x}) \geq 0) \rightarrow (p(\boldsymbol{u}, \boldsymbol{x}) \geq 0)))$.
	\item Consider the obtained quantifier-free formula $\Xi(\boldsymbol{u})$ as a constrain on $\boldsymbol{u}$. If $\Xi(\boldsymbol{u}) = \textit{FALSE}$ then report error. Otherwise use a constrain solver, such as DISCOVERER\cite{xia2007discoverer}, to find a solution $\boldsymbol{u}_0$.
	\item Let $\phi(\boldsymbol{x}) = p(\boldsymbol{u}_0, \boldsymbol{x})$, then $\phi(\boldsymbol{x}) \geq 0$ is an invariant.
\end{enumerate}

\section{General Case}
\label{sec:general}
We consider invariant verification and generation for general polynomial hybrid system in this section. The domain and initial set will be:
\begin{align*}
	\boldsymbol{H} &= S(\bigvee_{i=1}^I \bigwedge_{j=1}^{J_i} p_{ij}(\boldsymbol{x}) \rhd 0) \\
	\boldsymbol{I} &= S(\bigvee_{i=1}^N \bigwedge_{j=1}^{M_i} q_{ij}(\boldsymbol{x}) \rhd 0)
\end{align*}
and the possible invariant takes form:
\begin{equation*}
	\phi = \bigvee_{k=1}^K \bigwedge_{j=1}^{L_k} (p_{kl}(\boldsymbol{x}) \rhd 0)
\end{equation*}
where $\rhd \in \{ >, \geq \}$.

The basic idea is almost the same as that of last section. However, the complex boundaries of invariants, domain and initial set require some extra discussion. Strict proofs are often omitted as they are often repeat of what we did in last section.

\subsection{Inward Set and Inverse Inward Set: Definitions and Properties}
We define inward set as:
\begin{Definition}[Inward Set]
\label{def:in}
Given a hybrid system $(\boldsymbol{H}, \boldsymbol{I}, \boldsymbol{f})$, the inward set of a set $A$ is defined as: 
\begin{equation*}
	\mathrm{In}_f^{(t_0)}(A) \doteq \{ \boldsymbol{x}_0 \in \mathbb{R}^n\ |\ \forall \boldsymbol{x}: \boldsymbol{x}(t_0) = \boldsymbol{x}_0 \wedge \exists \epsilon > 0 \forall t \in (t_0, t_0 + \epsilon), \boldsymbol{x}(t) \in A \}
\end{equation*}
where $\boldsymbol{x}$ is a trajectory of the hybrid system.
\end{Definition}

Similarly, define inverse inward set as:
\begin{Definition}[Inverse Inward Set]
\label{def:ivin}
Given a hybrid system $(\boldsymbol{H}, \boldsymbol{I}, \boldsymbol{f})$, the inverse inward set of a set $A$ is defined as: 
\begin{equation*}
	\mathrm{IvIn}_f^{(t_0)}(A) \doteq \{ \boldsymbol{x}_0 \in \mathbb{R}^n\ |\ \exists \boldsymbol{x}: \boldsymbol{x}(t_0) = \boldsymbol{x}_0 \wedge \exists \epsilon > 0 \forall t \in (t_0 - \epsilon, t_0), \boldsymbol{x}(t) \in A \}
\end{equation*}
where $\boldsymbol{x}$ is a trajectory of the hybrid system.
\end{Definition}

Intuitively, $\boldsymbol{x}_0 \in \mathrm{In}_f^{(t_0)}(A)$ means any trajectories that pass $\boldsymbol{x}_0$ at $t_0$ must stay in $A$ for a positive time. While $\boldsymbol{x}_0 \in \mathrm{IvIn}_f^{(t_0)}(A)$ means any trajectories that pass $\boldsymbol{x}_0$ at $t_0$ must come from $A$.

The inward set and inverse inward set are useful when describing general continuous invariants: 

\begin{Theorem}
\label{thm:inIvin}
Given a hybrid system $(\boldsymbol{H}, \boldsymbol{I}, \boldsymbol{f})$, a set $\Psi$ is an invariant if and only if:
\begin{enumerate}
    \item $\boldsymbol{I} \subseteq \Psi$;
	\item $\forall t \geq 0, \forall \boldsymbol{x} (\boldsymbol{x} \in \Psi \cap \boldsymbol{H} \cap \mathrm{In}_f^{(t)}(\boldsymbol{H}) \Rightarrow \boldsymbol{x} \in \mathrm{In}_f^{(t)}(\Psi))$;
	\item $\forall t \geq 0, \forall \boldsymbol{x} (\boldsymbol{x} \in \Psi^c \cap \boldsymbol{H} \cap \mathrm{IvIn}_f^{(t)}(\boldsymbol{H}) \Rightarrow \boldsymbol{x} \in (\mathrm{IvIn}_f^{(t)}(\Psi))^c)$.
\end{enumerate}
\end{Theorem}

\begin{Proof}
The first condition of Definition{def:invariant} and the first condition of this theorem coincides, so we only need to consider the rest.

First let's consider the sufficient part. Recall Definition{def:invariant}, if $\Psi$ is not an invariant, then we have: there exists $t_0 \geq 0$, $\boldsymbol{x}_0 \in \Psi$ and $T_0 \geq 0$ such that:
\begin{equation*}
	(\forall t \in [t_0, t_0 + T_0], \boldsymbol{x}(t) \in \boldsymbol{H}) \nRightarrow (\forall t \in [t_0, t_0 + T_0], \boldsymbol{x}(t) \in \Psi)
\end{equation*}
which is equivalent to:
\begin{equation*}
	(\forall t \in [t_0, t_0 + T_0], \boldsymbol{x}(t) \in \boldsymbol{H}) \wedge (\exists t \in [t_0, t_0 + T_0], \boldsymbol{x}(t) \notin \Psi))
\end{equation*}
Take $t_z \in [t_0, t_0 + T_0]$ such that $\boldsymbol{x}(t_z) \notin \Psi$, and let
\begin{equation*}
	t_m = \inf \{ t \in [t_0, t_c]\ |\ \boldsymbol{x}(t) \notin \Psi \}
\end{equation*}
By the definition of $t_m$, $\boldsymbol{x}([t_0, t_m)) \subseteq \Psi$. Now consider $\boldsymbol{x}_m \doteq \boldsymbol{x}(t_m)$.

 If $\boldsymbol{x}_m \notin \Psi$, then $\boldsymbol{x}_m$ satisfies:
\begin{equation*}
	\boldsymbol{x_m} \in \Psi^c \cap \boldsymbol{H} \cap \mathrm{IvIn}_f^{(t)}(\boldsymbol{H}) \cap \mathrm{IvIn}_f^{(t)}(\Psi)
\end{equation*}
Which contradicts the third condition.

If $\boldsymbol{x}_m \in \Psi$, then $t_m < t_0 + T_0$, $\boldsymbol{x}_m$ satisfies:
\begin{equation*}
	\boldsymbol{x} \in \Psi \cap \boldsymbol{H} \cap \mathrm{In}_f^{(t)}(\boldsymbol{H}) \cap (\mathrm{In}_f^{(t)}(\Psi)))^c
\end{equation*}
Which contradicts the second condition.

Next we consider the necessary part. If the second condition doesn't hold, which is:
\begin{equation*}
	\exists t_0 \geq 0 ,\exists \boldsymbol{x}_0 \in \Psi \cap \boldsymbol{H} \cap \mathrm{In}_f^{(t_0)}(\boldsymbol{H}) \cap (\mathrm{In}_f^{(t_0)}(\Psi))^c
\end{equation*}
Recall Definition \ref{def:in}, that is to say: there exists a trajectory $\boldsymbol{x}$ satisfying $\boldsymbol{x}(t_0) = \boldsymbol{x}_0$ such that: $\forall \epsilon > 0 \exists t_{\epsilon} \in (t_0, t_0 + \epsilon) : \boldsymbol{x}(t) \notin \Psi$, which contradicts the second condition of Definition \ref{def:invariant}.

If the third condition doesn't hold, which is:
\begin{equation*}
	\exists t_0 \geq 0 ,\exists \boldsymbol{x}_0 \in \Psi^c \cap \boldsymbol{H} \cap \mathrm{IvIn}_f^{(t_0)}(\boldsymbol{H}) \cap \mathrm{IvIn}_f^{(t_0)}(\Psi)
\end{equation*}
Recall Definition \ref{def:ivin}, that is to say: there exists a trajectory $\boldsymbol{x}$ satisfying $\boldsymbol{x}(t_0) = \boldsymbol{x}_0$, $\exists \epsilon > 0 \forall t \in (t_0 - \epsilon, t_0) : \boldsymbol{x}(t) \in \Psi$, which also contradicts the second condition of Definition \ref{def:invariant}. 
\end{Proof}

Inward set and inverse inward set have the following properties:
\begin{Theorem}
\label{thm:property}
For any $A, B \subseteq \mathbb{R}^n$,
\begin{enumerate}
	\item If $A$ is a open set, then: $A \subseteq \mathrm{In}_f^{(t)}(A)$和$A \subseteq \mathrm{IvIn}_f^{(t)}(A)$ for any $t \in \mathbb{R}$.
	\item If $A \cap B = \emptyset$, then: $\mathrm{In}_f^{(t)}(A) \cap \mathrm{In}_f^{(t)}(B) = \emptyset$ and $\mathrm{IvIn}_f^{(t)}(A) \cap \mathrm{IvIn}_f^{(t)}(B) = \emptyset$ for any $t \in \mathbb{R}$.
\end{enumerate}
\end{Theorem}

\begin{Proof}
Proof can be obtained by checking definitions. Detailed proof is omitted here.
\end{Proof}

\subsection{Inward Set and Inverse Inward Set: Lie Derivatives}
We want to use Lie derivatives to describe inward set and inverse inward set. To do this, Theorem \ref{thm:lieDeri} should be extended to include the inverse part of trajectories:
\begin{Theorem}
\label{thm:pLieDeri}
Given polynomial $\phi$ and hybrid system $(\boldsymbol{H}, \boldsymbol{I}, \boldsymbol{f})$, $\gamma_{f, \phi}(\boldsymbol{x}_0, t) \neq 0$ if and only if $\boldsymbol{x}_0 \in S(\phi(\boldsymbol{x}) = 0)$,  and if we take $\boldsymbol{x}(t_0) = \boldsymbol{x}_0$, then it follows that: 
\begin{enumerate}
	\item if $\gamma_{f, \phi}(\boldsymbol{x}_0, t_0) < \infty$ and $\mathcal{L}_{t_0, f}^{\gamma_{f, \phi}(\boldsymbol{x}, t_0)} \phi (\boldsymbol{x}_0) > 0$, then: 
		\begin{equation*}
			\exists \epsilon > 0, \forall t \in (t_0, t_0 + \epsilon),\phi (\boldsymbol{x}(t)) > 0
		\end{equation*}
	\item if $\gamma_{f, \phi}(\boldsymbol{x}_0, t_0) < \infty$ and $\mathcal{L}_{t_0, f}^{\gamma_{f, \phi}(\boldsymbol{x}, t_0)} \phi (\boldsymbol{x}_0) < 0$, then: 
		\begin{equation*}
			\exists \epsilon > 0, \forall t \in (t_0, t_0 + \epsilon),\phi (\boldsymbol{x}(t)) < 0
		\end{equation*}
	\item If $\gamma_{f, \phi}(\boldsymbol{x}_0, t_0) < \infty$ and $(-1)^{\gamma_{f, \phi}(\boldsymbol{x}_0, t_0)} \mathcal{L}_{t_0, f}^{\gamma_{f, \phi}(\boldsymbol{x}, t_0)} \phi (\boldsymbol{x}_0) > 0$, then: 
		\begin{equation*}
			\exists \epsilon > 0, \forall t \in (t_0 - \epsilon, t_0),\phi (\boldsymbol{x}(t)) > 0
		\end{equation*}
	\item If $\gamma_{f, \phi}(\boldsymbol{x}_0, t_0) < \infty$ and $(-1)^{\gamma_{f, \phi}(\boldsymbol{x}_0, t_0)} \mathcal{L}_{t_0, f}^{\gamma_{f, \phi}(\boldsymbol{x}, t_0)} \phi (\boldsymbol{x}_0) < 0$, then: 
		\begin{equation*}
			\exists \epsilon > 0, \forall t \in (t_0 - \epsilon, t_0),\phi (\boldsymbol{x}(t)) < 0
		\end{equation*}
	\item if $\gamma_{f, \phi}(\boldsymbol{x}, t_0) = \infty$, then: 
		\begin{equation*}
			\exists \epsilon > 0, \forall t \in (t_0 - \epsilon, t_0 + \epsilon),\phi (\boldsymbol{x}(t)) = 0
		\end{equation*}
\end{enumerate}
\end{Theorem}

\begin{Proof}
The proof is almost the same of Theorem \ref{thm:lieDeri}. 
\end{Proof}

Then, let's consider inward set and inverse inward set of sets defined by a single polynomial. For convenience, we write $\mathrm{In}_f^{(t)}(\phi \rhd 0)$,  $\mathrm{IvIn}_f^{(t)}(\phi \rhd 0)$ to denote $\mathrm{In}_f^{(t)}(S(\phi \rhd 0))$ and $\mathrm{In}_f^{(t)}(S(\phi \rhd 0))$. We have: 

\begin{Theorem}
\label{thm:polyInIvin}
Given a hybrid system $(\boldsymbol{H}, \boldsymbol{I}, \boldsymbol{f})$ and polynomial $\phi$, we have: 
\begin{itemize}
	\item $\mathrm{In}_f^{(t)}(\phi > 0) = \Theta_+^{(t)}(\phi, \boldsymbol{f})$
	\item $\mathrm{In}_f^{(t)}(\phi \geq 0) = \Theta_+^{(t)}(\phi, \boldsymbol{f}) \cup \Theta_0^{(t)}(\phi, \boldsymbol{f})$
	\item $\mathrm{IvIn}_f^{(t)}(\phi > 0) = \Theta_-^{(t)}(\phi, \boldsymbol{f})$
	\item $\mathrm{IvIn}_f^{(t)}(\phi \geq 0) = \Theta_-^{(t)}(\phi, \boldsymbol{f}) \cup \Theta_0^{(t)}(\phi, \boldsymbol{f})$
\end{itemize}
for any $t \in \mathbb{R}$.

where: 
\begin{itemize}
	\item $\Theta_+^{(t)}(\phi, \boldsymbol{f}) \doteq \{ \boldsymbol{x} \in \mathbb{R}^n\ |\ \gamma_{\phi, f}(\boldsymbol{x}, t) < \infty \wedge \mathcal{L}_{t, f}^{\gamma_{\phi, f}(\boldsymbol{x}, t)} \phi(\boldsymbol{x}) > 0 \}$
	\item $\Theta_0^{(t)}(\phi, \boldsymbol{f}) \doteq \{ \boldsymbol{x} \in \mathbb{R}^n\ |\ \gamma_{\phi, f}(\boldsymbol{x}, t) = \infty\}$
	\item $\Theta_-^{(t)}(\phi, \boldsymbol{f}) \doteq \{ \boldsymbol{x} \in \mathbb{R}^n\ |\ \gamma_{\phi, f}(\boldsymbol{x}, t) < \infty \wedge (-1)^{\gamma_{\phi, f}(\boldsymbol{x}, t)} \mathcal{L}_{t, f}^{\gamma_{\phi, f}(\boldsymbol{x}, t)} \phi(\boldsymbol{x}) > 0 \}$
\end{itemize}
\end{Theorem}

\begin{Proof}
Combine Theorem \ref{thm:pLieDeri} and Definition \ref{def:in, def:ivin}, and apply the same method as used in the proof of Theorem \ref{thm:trans}.
\end{Proof}

For general semi-algebraic set
\begin{equation*}
	A \doteq \bigvee_{k=1}^K \bigwedge_{j=1}^{J_k} (p_{kj} \rhd 0)
\end{equation*}

we have:
\begin{Theorem}
\label{thm:semiInIvin}
\begin{align*}
	\mathrm{In}^{(t)}_f(A) &= \bigvee_{k=1}^K \bigwedge_{j=1}^{J_k} \mathrm{In}^{(t)}_f(p_{kj} \rhd 0) \\
	\mathrm{IvIn}^{(t)}_f(A) &= \bigvee_{k=1}^K \bigwedge_{j=1}^{J_k} \mathrm{IvIn}^{(t)}_f(p_{kj} \rhd 0) \\
\end{align*}
for any $t \in \mathbb{R}$.
\end{Theorem}

\begin{Proof}
Use Theorem \ref{thm:property}.
\end{Proof}

Now we are ready to give the Lie derivative description of inward set and inverse inward set: 
\begin{Theorem}
\label{thm:semiLie}
Given a hybrid system $(\boldsymbol{H}, \boldsymbol{I},  \boldsymbol{f})$ and semi-algebraic set $A$: 
\begin{equation*}
	A  = \bigvee_{k=1}^K (\bigwedge_{j=1}^{j_k} (p_{kj} \geq 0) \wedge \bigwedge_{j=j_k+1}^{J_{k}} (p_{kj} > 0))
\end{equation*}

we have: 
\begin{equation*}
\mathrm{In}_f^{(t)}(A) = \bigvee_{k=1}^K (\bigwedge_{j=1}^{j_k} (\Theta_+^{(t)}(p_{kj}, \boldsymbol{f}) \cup \Theta_0^{(t)}(\phi, \boldsymbol{f})) \wedge \bigwedge_{j=j_k+1}^{J_k} \Theta_+^{(t)}(\phi, \boldsymbol{f}))；
\end{equation*}
and:
\begin{equation*}
\mathrm{IvIn}_f^{(t)}(A) = \bigvee_{k=1}^K (\bigwedge_{j=1}^{j_k} (\Theta_-^{(t)}(p_{kj}, \boldsymbol{f}) \cup \Theta_0^{(t)}(\phi, \boldsymbol{f})) \wedge \bigwedge_{j=j_k+1}^{J_k} \Theta_-^{(t)}(\phi, \boldsymbol{f}))；
\end{equation*}
for any $t \in \mathbb{R}$.

The definition of $\Theta_+$, $\Theta_-$ and $\Theta_0$ can be found in Theorem \ref{thm:polyInIvin}.
\end{Theorem}

\begin{Proof}
Combine Theorem \ref{thm:polyInIvin} and Theorem \ref{thm:semiInIvin}.
\end{Proof}

\subsection{Verify Invariants of Polynomial Hybrid System: General Case}
In this subsection, we extend our verifying algorithm presented in last section to general semi-algebraic case. First we consider when the possible invariant is a polynomial, note that we can still use algorithms of \ref{sub:original} and \ref{sub:alternative} to compute the upper bound $N$ despite the complexity of boundaries. We have the following theorem: 
\begin{Theorem}
Take:
	\begin{align*}
		&\pi^{(0)}_+(\phi, \boldsymbol{f}, \boldsymbol{x}, t) \doteq \phi(\boldsymbol{x}) > 0 \\
		&\pi^{(i)}_+(\phi, \boldsymbol{f}, \boldsymbol{x}, t) \doteq (\bigwedge_{0 \leq j < i} \mathcal{L}_{t, f}^j \phi(\boldsymbol{x}) = 0) \wedge \mathcal{L}_{t, f}^i \phi(\boldsymbol{x}) > 0 \qquad i > 0 \\
		&\pi_+(\phi, \boldsymbol{f}, \boldsymbol{x}, t) \doteq \bigvee_{0 \leq i \leq N} \pi_+(\phi, \boldsymbol{f}, \boldsymbol{x}, t) \\
		&\pi_0(\phi, \boldsymbol{f}, \boldsymbol{x}, t) \doteq \bigvee_{0 \leq i \leq N} \mathcal{L}_{t,f}^i \phi(\boldsymbol{x}) = 0 \\
		&\pi^{(0)}_-(\phi, \boldsymbol{f}, \boldsymbol{x}, t) \doteq \phi(\boldsymbol{x}) < 0 \\
		&\pi^{(i)}_-(\phi, \boldsymbol{f}, \boldsymbol{x}, t) \doteq (\bigwedge_{0 \leq j < i} \mathcal{L}_{t, f}^j \phi(\boldsymbol{x}) = 0) \wedge \mathcal{L}_{t, f}^i \phi(\boldsymbol{x}) < 0 \qquad i > 0 \\
		&\pi_-(\phi, \boldsymbol{f}, \boldsymbol{x}, t) \doteq \bigvee_{0 \leq i \leq N} \pi_-(\phi, \boldsymbol{f}, \boldsymbol{x}, t)
	\end{align*}
Then:
	\begin{itemize}
		\item $\boldsymbol{x} \in \mathrm{In}_f^{(t)}(\phi > 0)$ if and only if formula $\pi_+(\phi, \boldsymbol{f}, \boldsymbol{x}, t)$ satisfies.
		\item $\boldsymbol{x} \in \mathrm{In}_f^{(t)}(\phi \geq 0)$ if and only if formula $\pi_{+,0}(\phi, \boldsymbol{f}, \boldsymbol{x}, t) \doteq \pi_+(\phi, \boldsymbol{f}, \boldsymbol{x}, t) \vee \pi_0(\phi, \boldsymbol{f}, \boldsymbol{x}, t)$ satisfies.
		\item $\boldsymbol{x} \in \mathrm{IvIn}_f^{(t)}(\phi > 0)$ if and only if formula $\pi_-(\phi, \boldsymbol{f}, \boldsymbol{x}, t)$ satisfies.
		\item $\boldsymbol{x} \in \mathrm{IvIn}_f{(t)}(\phi \geq 0)$ if and only if formula $\pi_{-,0}(\phi, \boldsymbol{f}, \boldsymbol{x}, t) \doteq \pi_-(\phi, \boldsymbol{f}, \boldsymbol{x}, t) \vee \pi_0(\phi, \boldsymbol{f}, \boldsymbol{x}, t)$satisfies.
	\end{itemize}
\end{Theorem}

\begin{Proof}
Use the same technique as Theorem \ref{thm:translate} to translate the conclusion of Theorem \ref{thm:polyInIvin} into finite length formula.
\end{Proof}

Now for general semi-algebraic invariants:
\begin{Theorem}
\label{thm:semiCond}
Given a hybrid system $(\boldsymbol{H}, \boldsymbol{I}, \boldsymbol{f})$ and semi-algebraic set $\Psi$ where:
\begin{align*}
	&\boldsymbol{H}  = \bigvee_{k=1}^K (\bigwedge_{j=1}^{j_k} (p_{kj} \geq 0) \wedge \bigwedge_{j=j_k+1}^{J_k} (p_{kj} > 0)) \\
	&\Psi = \bigvee_{m=1}^M (\bigwedge_{l=1}^{l_m} (p_{ml} \geq 0) \wedge \bigwedge_{l=l_m+1}^{L_m} (p_{ml} > 0)) 
\end{align*}
and let $\mathcal{I}$, $\mathcal{H}$, $\varPsi$ denote the formula that defines set $\boldsymbol{I}$, $\boldsymbol{H}$, $\Psi$ respectively. By our assumption, $\boldsymbol{I}$, $\boldsymbol{H}$, $\Psi$ are semi-algebraic sets, so $\mathcal{I}$, $\mathcal{H}$, $\varPsi$ are boolean combinations of polynomial formulas.

We have: $\Psi$ is an invariant of the hybrid system if and only if formula:
\begin{align*}
	&\forall \boldsymbol{x} : \mathcal{I} \rightarrow \varPsi \\
	&\forall t : (t < 0) \vee (\forall \boldsymbol{x} : \varPsi \wedge \mathcal{H} \wedge \xi_{+,H} \rightarrow \xi_{+, \Psi}) \\
	&\forall t : (t < 0) \vee (\forall \boldsymbol{x} : \neg \varPsi \wedge \mathcal{H} \wedge \xi_{-,H} \rightarrow \neg \xi_{-, \Psi})
\end{align*}
all satify.

Where:
\begin{align*}
	&\xi_{+, H} \doteq \bigvee_{k=1}^K(\bigwedge_{j=1}^{j_k} \pi_{+, 0}(p_{kj}, \boldsymbol{f}, \boldsymbol{x}, t) \wedge \bigwedge_{j=j_k+1}^{J_k} \pi_+(p_{kj}, \boldsymbol{f}, \boldsymbol{x}, t)) \\
	&\xi_{+, \Psi} \doteq \bigvee_{m=1}^M(\bigwedge_{l=1}^{l_k} \pi_{+, 0}(p_{ml}, \boldsymbol{f}, \boldsymbol{x}, t) \wedge \bigwedge_{l=l_k+1}^{\mathcal{L}_k} \pi_+(p_{ml}, \boldsymbol{f}, \boldsymbol{x}, t)) \\
	&\xi_{-, H} \doteq \bigvee_{k=1}^K(\bigwedge_{j=1}^{j_k} \pi_{-, 0}(p_{kj}, \boldsymbol{f}, \boldsymbol{x}, t) \wedge \bigwedge_{j=j_k+1}^{J_k} \pi_-(p_{kj}, \boldsymbol{f}, \boldsymbol{x}, t)) \\
	&\xi_{-, \Psi} \doteq \bigvee_{m=1}^M(\bigwedge_{l=1}^{l_k} \pi_{-, 0}(p_{ml}, \boldsymbol{f}, \boldsymbol{x}, t) \wedge \bigwedge_{l=l_k+1}^{\mathcal{L}_k} \pi_-(p_{ml}, \boldsymbol{f}, \boldsymbol{x}, t))
\end{align*}
\end{Theorem}

\begin{Proof}
Use the conclusion of Theorem \ref{thm:semiCond} and Theorem \ref{thm:semiInIvin} to translate the conclusion of Theorem \ref{thm:inIvin}.
\end{Proof}

Now we give the basic structure of the verifying algorithm:
\begin{enumerate}
	\item Use the original or alternative algorithm to compute the upper bound $N$ for every $p_{ml}$ and $p_{kj}$.
	\item Construct the formula in Theorem \ref{thm:semiCond}.
	\item Apply quantifier elimination algorithms on that formula.
	\item If the result is \emph{TRUE}, then $\Psi$ is an invariant; if the result is \emph{FALSE}, then $\Psi$ is not an invariant.
\end{enumerate}

\subsection{Generate Invariants of Hybrid System: General Case}
We also give the generating algorithm for general case: 
\begin{enumerate}
	\item Set semi-algebraic invariant template: 
		\begin{equation*}
			\Psi(\boldsymbol{u}, \boldsymbol{x}) = \bigvee_{m=1}^M (\bigwedge_{l=1}^{l_m} (p_{ml}(\boldsymbol{u}, \boldsymbol{x})\geq 0) \wedge \bigwedge_{l=l_m+1}^{L_m} (p_{ml}(\boldsymbol{u}, \boldsymbol{x}) > 0)) 
		\end{equation*}
		for some $p_{ml} \in \mathbb{R}[\boldsymbol{u}, \boldsymbol{x}]$.
	\item Use the original or alternative algorithm to compute the upper bound $N$ for every $p_{ml}$ and $p_{kj}$.
	\item Construct the formula in Theorem \ref{thm:semiCond}.
	\item Apply quantifier elimination algorithms on that formula.
	\item Consider the obtained quantifier-free formula $\Xi(\boldsymbol{u})$ as a constrain on $\boldsymbol{u}$. If $\Xi(\boldsymbol{u}) = \textit{FALSE}$ then report error. Otherwise use a constrain solver, such as DISCOVERER\cite{xia2007discoverer}, to find a solution $\boldsymbol{u}_0$.
	\item Let $\Psi_0(\boldsymbol{x}) = \Psi(\boldsymbol{u}_0, \boldsymbol{x})$, then $\Psi_0(\boldsymbol{x})$ is an invariant.
\end{enumerate}

\section{Conclusion}
\label{sec:conclusion}
In this article we propose a sound and complete algorithm to verify invariants of polynomial non-autonomous hybrid systems. From it we derive a sound and relatively complete algorithm to automatically generate invariants for such systems. "Relatively" means invariant generation needs a pre-defined template. 

Quantifier elimination in real closed field play a critical role in our approach. Since the problem has a double exponential time nature\cite{brown2007complexity}, time consumption of our algorithm grows very quickly as the number of variables grows. Still, besides its theoretical meanings, our approach has proved to be a possible choice for automatic invariant generation for small systems.

The chain of ideals generated by Lie derivatives has finite length. A primitive recursive upper bound of that length can be found\cite{socias1992length, figueira2011ackermannian}. This upper-bound is useful in constructive proof and time complexity analysis, but it's often too large to be practical comparing to the upper bound computed by the original and alternative algorithm presented in \ref{sub:original} and \ref{sub:alternative}. Thus it's not included in previous sections.

Further problems: how to use heuristic strategy in choosing template and verifying invariants; find sub-problems where our approach can be more competitive.
\bibliography{thesis}
\end{document}